from fastapi import FastAPI, File, UploadFile, HTTPException, Query
from app.kobert_model_loader import predict_scam_kobert 
from app.model_loader import get_model 
from app.utils import process_youtube_video, get_youtube_text, split_text 
from torchvision import transforms
from PIL import Image
import torch
import os
import numpy as np
from transformers import BertTokenizer, BertForSequenceClassification

app = FastAPI(title="ScamGuard AI API")

# --- ë”¥í˜ì´í¬ ëª¨ë¸ ë¡œë“œ ---
model, device = get_model("models/scamguard_model.pth")
# --- KoBERT ì‚¬ê¸° ìë§‰ íƒì§€ ëª¨ë¸ ë¡œë“œ ---
KO_MODEL_PATH = "models/kobert_model"
ko_tokenizer = BertTokenizer.from_pretrained(KO_MODEL_PATH)
ko_model = BertForSequenceClassification.from_pretrained(KO_MODEL_PATH)
ko_model.to(device)
ko_model.eval()

@app.get("/")
def read_root():
    return {"message": "Scam Guard AI Server is Running!"}

# --- ë”¥í˜ì´í¬ ì „ì²˜ë¦¬ ì„¤ì • ---
transformer = transforms.Compose(
    [
        transforms.ToPILImage(),
        transforms.Resize((299, 299)),
        transforms.ToTensor(),
        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),
    ]
)

# --- ë”¥í˜ì´í¬ íƒì§€ ì—”ë“œí¬ì¸íŠ¸ ---
@app.post("/deepfake")
async def predict_deepfake_from_url(url: str):
    # 1. ìœ íŠœë¸Œì—ì„œ ì–¼êµ´ ì¶”ì¶œ
    face_img = process_youtube_video(url)
    if face_img is None:
        raise HTTPException(
            status_code=400, detail="ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ì˜ìƒ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        )

    # 2. ì „ì²˜ë¦¬ ë° ì¶”ë¡ 
    input_tensor = transformer(face_img).unsqueeze(0).to(device)
    with torch.no_grad():
        output = model(input_tensor)
        prob = torch.nn.functional.softmax(output, dim=1)[0][1].item()

    return {
        "url": url,
        "is_fake": prob > 0.5,
        "confidence": round(prob * 100, 2),
        "message": "ğŸš¨ ë”¥í˜ì´í¬ ì˜ì‹¬" if prob > 0.5 else "âœ… ì •ìƒ ì˜ìƒ",
    }

# --- ìë§‰ ì‚¬ê¸° íƒì§€ ì—”ë“œí¬ì¸íŠ¸ ---
@app.post(
    "/youtube-scam", 
    tags=["ìë§‰ ë¶„ì„"], 
    summary="ìœ íŠœë¸Œ ìë§‰ ì‚¬ê¸° íŒë³„",
    description="KoBERT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìœ íŠœë¸Œ ìë§‰ì„ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ì„í•˜ê³  ì‚¬ê¸° ìœ„í—˜ë„ë¥¼ íŒë³„í•©ë‹ˆë‹¤."
)
async def analyze_text_scam(
    url: str = Query(..., description="ë¶„ì„í•  ìœ íŠœë¸Œ ì˜ìƒ URL", example="https://www.youtube.com/watch?v=ANCwJT3E7ko")
):
    video_id = url.split("v=")[-1].split("&")[0]
    raw_text = get_youtube_text(video_id)
    if not raw_text:
        raise HTTPException(status_code=400, detail="ìë§‰ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ëŠ” ì˜ìƒì…ë‹ˆë‹¤.")

    chunks = split_text(raw_text)
    scam_results = []
    max_prob = 0.0 
    
    for sentence in chunks:
        prob = predict_scam_kobert(sentence)
        
        if prob > max_prob:
            max_prob = prob
        
        if prob >= 0.7:
            scam_results.append({
                "text": sentence,
                "scam_probability": f"{round(prob * 100, 2)}%"
            })

    # 3ë‹¨ê³„ ìƒíƒœ íŒë³„ ë¡œì§ (ìœ„í—˜, ì£¼ì˜, ì•ˆì „)
    if max_prob >= 0.9:
        final_status = "ğŸš¨ ìœ„í—˜"
    elif max_prob >= 0.7:
        final_status = "âš ï¸ ì£¼ì˜"
    else:
        final_status = "âœ… ì•ˆì „"

    return {
        "url": url,
        "total_sentences": len(chunks),
        "highest_probability": f"{round(max_prob * 100, 2)}%",
        "detected_scams": scam_results,
        "status": final_status
    }

# --- ë°°ì¹˜ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸ ---
@app.get("/test-batch")
async def test_batch_images():
    # 1. í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ í´ë” ê²½ë¡œ ì„¤ì •
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    test_dir = os.path.join(base_dir, "test_images")

    if not os.path.exists(test_dir):
        return {"error": "test_images í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

    results = []
    # 2. í´ë” ë‚´ íŒŒì¼ë“¤ ë¦¬ìŠ¤íŒ… (png, jpg, jpegë§Œ ê³¨ë¼ë‚´ê¸°)
    image_files = [
        f for f in os.listdir(test_dir) if f.lower().endswith((".png", ".jpg", ".jpeg"))
    ]

    for filename in image_files:
        img_path = os.path.join(test_dir, filename)
        image = Image.open(img_path).convert("RGB")

        # ğŸ’¡ PIL ì´ë¯¸ì§€ë¥¼ Numpy ë°°ì—´ë¡œ ë³€í™˜í•´ì„œ transformerì— ì „ë‹¬
        image_np = np.array(image)
        input_tensor = transformer(image_np).unsqueeze(0).to(device)
        with torch.no_grad():
            output = model(input_tensor)
            prob = torch.nn.functional.softmax(output, dim=1)[0][1].item()

        confidence = round(prob * 100, 2)
        results.append(
            {
                "filename": filename,
                "is_fake": confidence > 50,
                "confidence": f"{confidence}%",
                "status": "ğŸš¨ ë”¥í˜ì´í¬ ì˜ì‹¬" if confidence > 50 else "âœ… ì •ìƒ",
            }
        )

    # 4. ì „ì²´ ê²°ê³¼ ë°˜í™˜
    return {"total_count": len(results), "predictions": results}
